# -*- coding: utf-8 -*-
"""Untitled47.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1__f7p9tc0RDszN9rr--hOhZFR1TW_jXx
"""

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer
import string

nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')

filename = "/content/drive/MyDrive/Conflation.txt.txt"
with open (filename,'r',encoding='utf-8') as file:
  text = file.read()

  print("original Text:\n" , text)

token = word_tokenize(text.lower())

stop_words = set(stopwords.words('english'))
filter_token = [ ]
for word in token:
  if word.isalpha() and word not in stop_words:
       filter_token.append(word)
token = filter_token

stemmer = PorterStemmer()
stemmed_words = [stemmer.stem(word) for word in token]

print("after Stemming:\n",' '.join(stemmed_words))

lemmatizer = WordNetLemmatizer()
lemmatizer_words = [lemmatizer.lemmatize(word) for word in token]

print("After Lemmatizer\n"," ".join(lemmatizer_words))

from collections import Counter
freq = Counter(stemmed_words)
print("Document Representative (Word Frequency):")
for word , count in freq.most_common(10):
  print(f"{word}:{count}")